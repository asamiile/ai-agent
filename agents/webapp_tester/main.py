import os
import sys
import re
from datetime import datetime
from playwright.sync_api import sync_playwright
import google.generativeai as genai
from dotenv import load_dotenv

load_dotenv()

# ãƒ‘ã‚¹è¨­å®šï¼ˆcommonãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãªã©ãŒä½¿ãˆã‚‹ã‚ˆã†ã«ï¼‰
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../")))

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®èª­ã¿è¾¼ã¿
from agents.webapp_tester.prompts import PLANNING_PROMPT, CODING_PROMPT

# APIã‚­ãƒ¼è¨­å®š
API_KEY = os.getenv("GOOGLE_AI_STUDIO_API_KEY")
if not API_KEY:
    print("ã‚¨ãƒ©ãƒ¼: GOOGLE_AI_STUDIO_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    sys.exit(1)

genai.configure(api_key=API_KEY)
model = genai.GenerativeModel('gemini-2.5-flash')

def fetch_page_content(url: str):
    """Playwrightã§ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã€HTMLæ§‹é€ ã‚’ç°¡æ˜“åŒ–ã—ã¦å–å¾—ã™ã‚‹"""
    print(f"ğŸŒ ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹ä¸­: {url}")
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()
        try:
            page.goto(url, timeout=30000, wait_until="domcontentloaded")

            # ãƒšãƒ¼ã‚¸ã®èª­ã¿è¾¼ã¿ã‚’å¾…ã¤ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
            try:
                page.wait_for_load_state("networkidle", timeout=10000)
            except Exception:
                print("âš ï¸ networkidle timeout, proceeding with domcontentloaded...")
                page.wait_for_load_state("domcontentloaded")

            # ãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾— (for AI prompt)
            text = page.evaluate("document.body.innerText")

            # ãƒªãƒ³ã‚¯ã‚’å–å¾— (for crawling)
            links = page.evaluate("""
                Array.from(document.querySelectorAll('a')).map(a => a.href)
            """)

            browser.close()
            return text, links
        except Exception as e:
            print(f"âŒ ãƒšãƒ¼ã‚¸å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return "", []

def generate_test_code(url: str, page_content: str):
    """Geminiã«ãƒ†ã‚¹ãƒˆè¨ˆç”»ã¨ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã•ã›ã‚‹"""

    # 1. ãƒ†ã‚¹ãƒˆè¨ˆç”»ã®ä½œæˆ
    print("ğŸ¤” AIãŒãƒ†ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ªã‚’è€ƒæ¡ˆä¸­...")
    plan_prompt = PLANNING_PROMPT.format(url=url) + f"\n\n## ãƒšãƒ¼ã‚¸ã‚³ãƒ³ãƒ†ãƒ³ãƒ„(æŠœç²‹)\n{page_content[:10000]}" # æ–‡å­—æ•°åˆ¶é™å¯¾ç­–

    plan_response = model.generate_content(plan_prompt)
    test_plan = plan_response.text
    print(f"\n--- ğŸ“ ãƒ†ã‚¹ãƒˆè¨ˆç”» ---\n{test_plan}\n--------------------")

    # 2. ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ã®ç”Ÿæˆ
    print("ğŸ’» AIãŒãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè£…ä¸­...")
    code_prompt = CODING_PROMPT.format(url=url, test_plan=test_plan)

    code_response = model.generate_content(code_prompt)
    code_text = code_response.text

    # Markdownã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‹ã‚‰Pythonã‚³ãƒ¼ãƒ‰ã ã‘ã‚’æŠ½å‡º
    match = re.search(r"```python\n(.*?)\n```", code_text, re.DOTALL)
    if match:
        code = match.group(1)
    else:
        # ãƒ–ãƒ­ãƒƒã‚¯ãŒãªã„å ´åˆã¯ãã®ã¾ã¾è¿”ã™ï¼ˆã¾ãŸã¯ã‚¨ãƒ©ãƒ¼å‡¦ç†ï¼‰
        code = code_text.replace("```python", "").replace("```", "")

    return code, test_plan

def save_test_file(code: str, url: str):
    """ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹"""
    # URLã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆï¼ˆä¾‹: google.com -> test_google_com.pyï¼‰
    domain = re.sub(r'^https?://', '', url).split('/')[0].replace('.', '_')
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # å®Ÿè¡Œã”ã¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ: tests/generated/{timestamp}_{domain}/
    save_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "tests", "generated", f"{timestamp}_{domain}")
    os.makedirs(save_dir, exist_ok=True)

    filename = f"test_{domain}.py"
    filepath = os.path.join(save_dir, filename)

    with open(filepath, "w", encoding="utf-8") as f:
        f.write(code)

    print(f"âœ… ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filepath}")
    return filepath, save_dir

def run_test(filepath: str):
    """ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ã‚’pytestã§å®Ÿè¡Œã™ã‚‹"""
    print(f"ğŸš€ ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œä¸­: {filepath}")
    import subprocess

    try:
        # pytestã‚’å®Ÿè¡Œ (ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ120ç§’)
        result = subprocess.run(
            ["pytest", filepath],
            capture_output=True,
            text=True,
            timeout=120
        )
        return result.returncode, result.stdout, result.stderr
    except subprocess.TimeoutExpired as e:
        print(f"â° ãƒ†ã‚¹ãƒˆå®Ÿè¡ŒãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ (120ç§’): {filepath}")
        return 124, e.stdout or "", (e.stderr or "") + "\nTimeoutExpired: Test execution exceeded 120 seconds."
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return 1, "", str(e)

def generate_report(url: str, plan: str, retcode: int, stdout: str, stderr: str, save_dir: str, filename: str = "report.md"):
    """ãƒ†ã‚¹ãƒˆçµæœã®ãƒ¬ãƒãƒ¼ãƒˆ(Markdown)ã‚’ä½œæˆã™ã‚‹"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    status = "âœ… PASS" if retcode == 0 else "âŒ FAIL"

    # ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    screenshots = []
    try:
        all_files = os.listdir(save_dir)
        screenshots = sorted([f for f in all_files if f.endswith('.png')])
    except Exception as e:
        print(f"âš ï¸ ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

    # ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ
    screenshot_section = ""
    if screenshots:
        screenshot_section = "\n## 3. Screenshots\n\n"
        screenshot_section += f"**Total Screenshots:** {len(screenshots)}\n\n"
        for img in screenshots:
            # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ã‚¿ã‚¤ãƒˆãƒ«ã¨ã—ã¦ä½¿ç”¨ï¼ˆæ‹¡å¼µå­ã‚’é™¤ãï¼‰
            title = img.replace('.png', '').replace('_', ' ').title()
            screenshot_section += f"### {title}\n"
            screenshot_section += f"![{title}](./{img})\n\n"

    report_content = f"""# Webapp Test Report

**Target URL:** {url}
**Date:** {timestamp}
**Status:** {status}

## 1. Test Plan
{plan}

## 2. Execution Result
**Return Code:** {retcode}

### Stdout
```text
{stdout}
```

### Stderr
```text
{stderr}
```
{screenshot_section}"""
    report_path = os.path.join(save_dir, filename)
    with open(report_path, "w", encoding="utf-8") as f:
        f.write(report_content)

    print(f"ğŸ“ ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¾ã—ãŸ: {report_path}")
    return report_path

def filter_links(base_url: str, links: list[str]) -> list[str]:
    """ãƒªãƒ³ã‚¯ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¦ã€åŒä¸€ãƒ‰ãƒ¡ã‚¤ãƒ³ã®æœ‰åŠ¹ãªURLã®ã¿ã‚’è¿”ã™ï¼ˆé †åºä¿æŒï¼‰"""
    unique_links = []
    seen = set()
    base_domain = re.sub(r'^https?://', '', base_url).split('/')[0]

    for link in links:
        # URLã‚’æ­£è¦åŒ–
        link = link.split('#')[0].rstrip('/')

        # ç„¡åŠ¹ãªãƒªãƒ³ã‚¯ã‚’é™¤å¤–
        if not link or link.startswith(('mailto:', 'tel:', 'javascript:')):
            continue

        # åŒä¸€ãƒ‰ãƒ¡ã‚¤ãƒ³ã‹ãƒã‚§ãƒƒã‚¯
        if base_domain not in link:
            continue

        # è‡ªåˆ†è‡ªèº«ã‚’é™¤å¤–
        if link == base_url.rstrip('/'):
            continue

        if link not in seen:
            seen.add(link)
            unique_links.append(link)

    return unique_links

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆã—ãŸã„URLã‚’æŒ‡å®šï¼ˆå¼•æ•°ã§ã‚‚å¯ï¼‰
    start_url = sys.argv[1] if len(sys.argv) > 1 else "https://example.com"

    # å®Ÿè¡ŒIDï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼‰ã‚’ç”Ÿæˆ
    domain = re.sub(r'^https?://', '', start_url).split('/')[0].replace('.', '_')
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    run_id = f"{timestamp}_{domain}"

    # ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    base_save_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "tests", "generated", run_id)
    os.makedirs(base_save_dir, exist_ok=True)

    # ã‚¯ãƒ­ãƒ¼ãƒªãƒ³ã‚°ã¨ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
    urls_to_process = [start_url]
    processed_urls = set()
    max_pages = 6 # ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ + 5ã‚µãƒ–ãƒšãƒ¼ã‚¸ (é †åºä¿æŒã§ä¸»è¦ãƒšãƒ¼ã‚¸ã‚’å„ªå…ˆ)

    results = []

    print(f"ğŸš€ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚’é–‹å§‹ã—ã¾ã™: {start_url}")
    print(f"ğŸ“‚ ä¿å­˜å…ˆ: {base_save_dir}")

    while urls_to_process and len(processed_urls) < max_pages:
        current_url = urls_to_process.pop(0)
        if current_url in processed_urls:
            continue

        print(f"\nğŸ” Processing: {current_url} ({len(processed_urls) + 1}/{max_pages})")

        content, links = fetch_page_content(current_url)

        if not content:
            print(f"âŒ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {current_url}")
            continue

        # æ–°ã—ã„ãƒªãƒ³ã‚¯ã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ ï¼ˆãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã®å ´åˆã®ã¿ï¼‰
        if len(processed_urls) == 0: # Only filter links from the initial page to find subpages
            valid_links = filter_links(start_url, links)
            # é‡è¤‡ã‚’é¿ã‘ã¤ã¤è¿½åŠ 
            for link in valid_links:
                if link not in processed_urls and link not in urls_to_process:
                    urls_to_process.append(link)
            print(f"ğŸ”— ç™ºè¦‹ã—ãŸãƒªãƒ³ã‚¯: {len(valid_links)}ä»¶ (ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ : {len(urls_to_process)}ä»¶)")

        # ãƒ†ã‚¹ãƒˆç”Ÿæˆã¨å®Ÿè¡Œ
        code, test_plan = generate_test_code(current_url, content)
        if code:
            # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’URLã«åŸºã¥ã„ã¦ç”Ÿæˆ
            page_slug = re.sub(r'^https?://', '', current_url).rstrip('/').replace('/', '_').replace('.', '_').replace(':', '_')
            filename = f"test_{page_slug}.py"
            filepath = os.path.join(base_save_dir, filename)

            with open(filepath, "w", encoding="utf-8") as f:
                f.write(code)
            print(f"âœ… ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ä¿å­˜: {filename}")

            # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
            retcode, stdout, stderr = run_test(filepath)
            status = "PASS" if retcode == 0 else "FAIL"

            # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            report_filename = f"report_{page_slug}.md"
            report_path = generate_report(current_url, test_plan, retcode, stdout, stderr, base_save_dir, report_filename)

            results.append({
                "url": current_url,
                "status": status,
                "report": report_filename
            })

        processed_urls.add(current_url)

    # ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã®ä½œæˆ
    summary_path = os.path.join(base_save_dir, "summary.md")
    with open(summary_path, "w", encoding="utf-8") as f:
        f.write(f"# Test Run Summary\n\n")
        f.write(f"**Target:** {start_url}\n")
        f.write(f"**Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write("| URL | Status | Report |\n")
        f.write("| --- | --- | --- |\n")
        for res in results:
            status_icon = "âœ…" if res["status"] == "PASS" else "âŒ"
            f.write(f"| {res['url']} | {status_icon} {res['status']} | [View Report]({res['report']}) |\n")

    print(f"\nğŸ‰ å…¨ã¦ã®ãƒ†ã‚¹ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚ã‚µãƒãƒªãƒ¼: {summary_path}")
